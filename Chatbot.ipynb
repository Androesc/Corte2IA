{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input, decode_predictions\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import random\n",
        "import re\n",
        "import os\n",
        "from PIL import Image\n",
        "import io\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "def cargar_modelo_imagenes():\n",
        "    modelo_base = MobileNetV2(weights='imagenet', include_top=True)\n",
        "    return modelo_base\n",
        "\n",
        "def preprocesar_imagen(ruta_imagen=None, imagen_pil=None):\n",
        "    if ruta_imagen:\n",
        "        img = image.load_img(ruta_imagen, target_size=(224, 224))\n",
        "    elif imagen_pil:\n",
        "        img = imagen_pil.resize((224, 224))\n",
        "    else:\n",
        "        raise ValueError(\"Debes proporcionar una ruta o una imagen PIL.\")\n",
        "    x = image.img_to_array(img)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    x = preprocess_input(x)\n",
        "    return x\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "modelo_imagenes = cargar_modelo_imagenes()\n",
        "print(\"Modelos base cargados correctamente.\")\n",
        "\n",
        "def analizar_imagen(ruta_imagen=None, imagen_pil=None):\n",
        "    img_array = preprocesar_imagen(ruta_imagen, imagen_pil)\n",
        "    if img_array is None:\n",
        "        return \"No se pudo procesar la imagen.\"\n",
        "    preds = modelo_imagenes.predict(img_array)\n",
        "    resultados = decode_predictions(preds, top=3)[0]\n",
        "    descripcion = \"En esta imagen puedo ver: \"\n",
        "    etiquetas = []\n",
        "    for (_, nombre, _) in resultados:\n",
        "        etiquetas.append(nombre.replace('_', ' '))\n",
        "    descripcion += \", \".join(etiquetas) + \".\"\n",
        "    contexto = interpretar_contexto_imagen(etiquetas)\n",
        "    if contexto:\n",
        "        descripcion += f\" {contexto}\"\n",
        "    return descripcion\n",
        "\n",
        "def interpretar_contexto_imagen(etiquetas):\n",
        "    contexto = \"\"\n",
        "    etiquetas = [e.lower() for e in etiquetas]\n",
        "    if any(obj in etiquetas for obj in ['dog', 'cat', 'puppy', 'kitten']):\n",
        "        contexto = \"Parece una escena tranquila y amigable con animales.\"\n",
        "    elif any(obj in etiquetas for obj in ['person', 'man', 'woman']):\n",
        "        contexto = \"Podría haber interacción humana en la imagen.\"\n",
        "    elif any(obj in etiquetas for obj in ['forest', 'mountain', 'ocean', 'beach']):\n",
        "        contexto = \"La imagen muestra un entorno natural o relajante.\"\n",
        "    elif any(obj in etiquetas for obj in ['car', 'bus', 'airplane']):\n",
        "        contexto = \"Parece una escena de transporte o movimiento.\"\n",
        "    elif any(obj in etiquetas for obj in ['weapon', 'knife', 'gun']):\n",
        "        contexto = \"Advertencia: la imagen podría contener contenido sensible.\"\n",
        "    return contexto\n",
        "\n",
        "patrones_conversacion = {\n",
        "    \"saludos\": [r\"hola\", r\"buenos días\", r\"buenas tardes\", r\"hey\", r\"saludos\"],\n",
        "    \"preguntas_imagen\": [r\"qué ves en (la|esta) imagen\", r\"describe (la|esta) imagen\", r\"qué hay en (la|esta) imagen\", r\"qué puedes ver\", r\"analiza (la|esta) imagen\"],\n",
        "    \"consulta_psicologica\": [r\"me siento (triste|feliz|ansioso|preocupado|estresado)\", r\"tengo problemas con\", r\"no puedo (dormir|concentrarme|estudiar)\", r\"necesito ayuda con mis emociones\", r\"cómo puedo manejar (el estrés|la ansiedad|la depresión)\"],\n",
        "    \"consulta_academica\": [r\"no entiendo (este tema|esta materia)\", r\"cómo puedo estudiar mejor\", r\"tengo dificultades con\", r\"necesito ayuda con mis estudios\", r\"cómo mejorar (mi concentración|mi memoria|mis notas)\"],\n",
        "    \"despedida\": [r\"adiós\", r\"hasta luego\", r\"nos vemos\", r\"chao\", r\"bye\"]\n",
        "}\n",
        "\n",
        "respuestas = {\n",
        "    \"saludos\": [\"\\u00a1Hola! ¿En qué puedo ayudarte hoy?\", \"\\u00a1Saludos! Soy un asistente virtual. Puedo analizar imágenes y conversar contigo.\", \"\\u00a1Buen día! Estoy aquí para ayudarte con tus consultas e imágenes.\"],\n",
        "    \"preguntas_imagen_sin_contexto\": [\"Para analizar una imagen, necesito que me la proporciones primero.\", \"No tengo ninguna imagen para analizar. ¿Podrías compartir una?\", \"Necesito ver una imagen antes de poder describirla.\"],\n",
        "    \"consulta_psicologica\": [\"Entiendo cómo te sientes. ¿Podrías contarme más sobre eso?\", \"Es normal tener esos sentimientos. ¿Qué crees que los está causando?\", \"Gracias por compartir eso conmigo. Te escucho. ¿Desde cuándo te sientes así?\"],\n",
        "    \"consulta_academica\": [\"Aprender puede ser desafiante. ¿Con qué tema específico estás teniendo dificultades?\", \"Cada persona tiene su propio estilo de aprendizaje. ¿Has identificado qué métodos funcionan mejor para ti?\", \"El éxito académico requiere estrategia. ¿Has probado crear un horario de estudio?\"],\n",
        "    \"despedida\": [\"\\u00a1Hasta pronto! Fue un placer ayudarte.\", \"\\u00a1Adiós! Si necesitas más ayuda, aquí estaré.\", \"\\u00a1Que tengas un excelente día! Regresa cuando necesites apoyo.\"],\n",
        "    \"default\": [\"Interesante. Cuéntame más.\", \"No estoy seguro de entender. ¿Podrías explicarlo de otra manera?\", \"Estoy aquí para ayudarte. ¿Puedes ser más específico?\"]\n",
        "}\n",
        "\n",
        "def procesar_texto(texto):\n",
        "    texto = texto.lower()\n",
        "    texto = re.sub(r'[^a-záéíóúñü0-9\\s]', '', texto)\n",
        "    tokens = word_tokenize(texto)\n",
        "    tokens_lematizados = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "    return tokens_lematizados\n",
        "\n",
        "def identificar_intencion(texto):\n",
        "    texto = texto.lower()\n",
        "    for categoria, patrones in patrones_conversacion.items():\n",
        "        for patron in patrones:\n",
        "            if re.search(patron, texto):\n",
        "                return categoria\n",
        "    return \"default\"\n",
        "\n",
        "class AsistenteVirtual:\n",
        "    def __init__(self):\n",
        "        self.modelo_imagenes = modelo_imagenes\n",
        "        self.imagen_actual = None\n",
        "        self.analisis_imagen_actual = None\n",
        "        self.contexto_conversacion = []\n",
        "\n",
        "    def procesar_imagen(self, ruta_imagen=None, imagen_pil=None):\n",
        "        try:\n",
        "            self.imagen_actual = imagen_pil if imagen_pil else Image.open(ruta_imagen)\n",
        "            self.analisis_imagen_actual = analizar_imagen(ruta_imagen, imagen_pil)\n",
        "            return self.analisis_imagen_actual\n",
        "        except Exception as e:\n",
        "            return f\"Ocurrió un error al procesar la imagen: {str(e)}\"\n",
        "\n",
        "    def responder(self, texto_usuario):\n",
        "        categoria = identificar_intencion(texto_usuario)\n",
        "        if categoria == \"preguntas_imagen\":\n",
        "            if self.analisis_imagen_actual:\n",
        "                respuesta = self.analisis_imagen_actual\n",
        "            else:\n",
        "                respuesta = random.choice(respuestas[\"preguntas_imagen_sin_contexto\"])\n",
        "        elif categoria in respuestas:\n",
        "            respuesta = random.choice(respuestas[categoria])\n",
        "        else:\n",
        "            respuesta = random.choice(respuestas[\"default\"])\n",
        "        self.contexto_conversacion.append({\"usuario\": texto_usuario, \"respuesta\": respuesta})\n",
        "        return respuesta\n",
        "\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "def generador_ejercicios(tema, dificultad):\n",
        "    if tema.lower() == \"matemáticas\":\n",
        "        if dificultad == \"básico\":\n",
        "            return [\"¿Cuánto es 3 + 4?\", \"Resuelve: 8 - 2\"]\n",
        "        elif dificultad == \"intermedio\":\n",
        "            return [\"Resuelve: 12 × 5\", \"Calcula: 72 ÷ 8\"]\n",
        "        elif dificultad == \"avanzado\":\n",
        "            return [\"Calcula la derivada de x^2\", \"Integra: ∫ x dx\"]\n",
        "    elif tema.lower() == \"vocabulario\":\n",
        "        return [\"Escribe una oración con la palabra 'amistad'.\", \"Define: 'empatía'\"]\n",
        "    return [\"Lo siento, no tengo ejercicios para ese tema.\"]\n",
        "\n",
        "def analisis_sentimiento(texto):\n",
        "    sia = SentimentIntensityAnalyzer()\n",
        "    score = sia.polarity_scores(texto)['compound']\n",
        "    if score >= 0.5:\n",
        "        return \"positivo\"\n",
        "    elif score <= -0.5:\n",
        "        return \"negativo\"\n",
        "    else:\n",
        "        return \"neutral\"\n",
        "\n",
        "class AsistenteVirtualMejorado(AsistenteVirtual):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def analizar_sentimiento_usuario(self, texto):\n",
        "        return analisis_sentimiento(texto)\n",
        "\n",
        "    def recomendar_recursos(self, tema, sentimiento=None):\n",
        "        if sentimiento == \"negativo\":\n",
        "            return f\"Te recomiendo un descanso y luego repasar lo básico de {tema}. Aquí tienes una guía práctica.\"\n",
        "        elif sentimiento == \"positivo\":\n",
        "            return f\"¡Genial! Puedes intentar ejercicios más desafiantes sobre {tema}.\"\n",
        "        else:\n",
        "            return f\"Consulta este recurso introductorio sobre {tema}.\"\n",
        "\n",
        "    def crear_plan_estudio(self, tema, nivel):\n",
        "        return f\"Plan para {tema} ({nivel}):\\n1. Revisión de conceptos clave.\\n2. Práctica guiada.\\n3. Evaluación semanal.\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sf3w8ihG0fw2",
        "outputId": "2fd8d2d0-b3d8-4376-cc08-63fd1094ac0b"
      },
      "id": "sf3w8ihG0fw2",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelos base cargados correctamente.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}